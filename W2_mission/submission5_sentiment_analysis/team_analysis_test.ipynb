{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time  # sleep\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from konlpy.tag import Okt, Mecab\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "plt.rcParams['font.family'] = 'AppleGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(keywords: List[str]) -> pd.DataFrame:\n",
    "    driver = webdriver.Chrome()\n",
    "    data = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        driver.get(\"http://www.naver.com\")\n",
    "        elem = driver.find_element(By.ID, \"query\")\n",
    "        elem.send_keys(f\"{keyword}_오너평가\")\n",
    "        elem.send_keys(Keys.RETURN)\n",
    "        time.sleep(4)\n",
    "\n",
    "        # check counts to repeatedly scroll\n",
    "        count_value = driver.find_element(By.CLASS_NAME, \"_count\").text\n",
    "        element = driver.find_element(\n",
    "            By.XPATH, '//*[@id=\"main_pack\"]/div[3]/div[2]/div/div/div[5]'\n",
    "        )\n",
    "\n",
    "        # focus to specific element\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(element).perform()\n",
    "\n",
    "        # javascript scroll script\n",
    "        scroll_script = \"\"\"\n",
    "            var element = arguments[0];\n",
    "            var deltaY = arguments[1];\n",
    "            element\n",
    "            element.scrollTop += deltaY;\n",
    "        \"\"\"\n",
    "        \n",
    "        # scroll down repeatedly to load more reviews\n",
    "        for _ in range(int(count_value)//10+2):\n",
    "            driver.execute_script(scroll_script, element, 2700)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        time.sleep(3)\n",
    "        reviews = driver.find_elements(By.CLASS_NAME, 'u_cbox_comment_box')\n",
    "        \n",
    "        for review in reviews:\n",
    "            # extract\n",
    "            try:\n",
    "                rate = review.find_element(\n",
    "                    By.CLASS_NAME, 'u_cbox_info').text.replace(\"\\n\", \" \")\n",
    "                each_count_rates = review.find_element(\n",
    "                    By.CLASS_NAME, 'u_cbox_multirating_eachcount').text.replace(\"\\n\", \" \")\n",
    "                comments = review.find_element(\n",
    "                    By.CLASS_NAME, 'u_cbox_text_wrap').text.replace(\"\\n\", \" \")\n",
    "                recomm_sets = review.find_element(\n",
    "                    By.CLASS_NAME, 'u_cbox_recomm_set').text.replace(\"\\n\", \" \")\n",
    "                data.append([keyword, rate, each_count_rates, comments, recomm_sets])\n",
    "            except:\n",
    "                print(review.text)\n",
    "    df = pd.DataFrame(data, columns=[\"차종\", \"평점 평균\", \"기능 점수\", \"리뷰\", \"공감\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_functional_points(line: str) -> dict:\n",
    "    line = line.split(\" \")\n",
    "    data = dict()\n",
    "    for ch in line[2:]:\n",
    "        text, num = \"\", \"\"\n",
    "        if ch[-2:] == '10':\n",
    "            text, num = ch[:-2], int(ch[-2:])\n",
    "        else:\n",
    "            text, num = ch[:-1], int(ch[-1])\n",
    "        data[text] = num\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, method: str = 'okt') -> str:\n",
    "    # 텍스트 전처리\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수 문자 제거\n",
    "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "    \n",
    "    # 불용어 제거\n",
    "    if method == 'okt':\n",
    "        okt = Okt()\n",
    "        tokens = okt.pos(text, norm=True, stem=True)\n",
    "        words = [word for word, pos in tokens if pos in ['Noun', 'Verb', 'Adjective']]\n",
    "        \n",
    "        stopwords = set([\n",
    "            '은', '는', '이', '가', '를', '에', '의', '도', '다', '한', '하', \"타다\",\n",
    "            '있다', '들다', '하다', '없다', '되다', \"포터\", \"아반떼\", \"소나타\", \"투싼\", \n",
    "            \"팰리세이드\", \"그랜저\", \"아이오닉6\", \"아이오닉\",\n",
    "        ])\n",
    "        words = [word.replace(rpl_ch, \"\") for word in words for rpl_ch in ['하다','이다','되다', '가다'] if word.endswith(rpl_ch)]\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        words = [word for word in words if len(word) > 1]\n",
    "    else:\n",
    "        mecab = Mecab()\n",
    "        tokens = mecab.pos(text)\n",
    "        words = [word for word, pos in tokens if pos in ['NNG', 'VV', 'VA']]\n",
    "        words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recomm_unrecomm(line: str) -> dict:\n",
    "    line = line.split(\" \")\n",
    "    data = dict()\n",
    "    for i in range(1, len(line)):\n",
    "        if line[i] == \"공감\":\n",
    "            data[line[i]] = int(line[i+1])\n",
    "        elif line[i] == \"비공감\":\n",
    "            data[line[i]] = int(line[i+1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df: pd.DataFrame, method: str = 'okt'):\n",
    "    # 평점 평균\n",
    "    df['평점 평균'] = df['평점 평균'].apply(lambda x: float(x.split(\" \")[-1]))\n",
    "    \n",
    "    # 기능 점수 => 각 항목으로 분리\n",
    "    df['기능 점수'] = df['기능 점수'].apply(extract_functional_points)\n",
    "    for key in df['기능 점수'][0].keys():\n",
    "        df[key] = df['기능 점수'].apply(lambda x: x.get(key, 0))\n",
    "    \n",
    "    # 리뷰\n",
    "    df['리뷰'] = df['리뷰'].apply(lambda x: preprocess_text(x, method))\n",
    "    \n",
    "    # 공감\n",
    "    df['공감/비공감'] = df['공감'].apply(extract_recomm_unrecomm)\n",
    "    for key in df['공감/비공감'][0].keys():\n",
    "        df[key] = df['공감/비공감'].apply(lambda x: x.get(key, 0))\n",
    "    df.drop(['기능 점수', '공감/비공감'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정/부정 분할\n",
    "def split_pos_neg_by_spec_col(\n",
    "    boundary_col_name: str,\n",
    "    boundary: float,\n",
    "    model_name: str,\n",
    "    df: pd.DataFrame, \n",
    ") ->  List[str]: \n",
    "    if model_name == \"전체\":\n",
    "        pos_df = df[df[boundary_col_name] >= boundary]\n",
    "        neg_df = df[df[boundary_col_name] < boundary]\n",
    "    else:\n",
    "        pos_df = df[(df[boundary_col_name] >= boundary) & (df['차종'] == model_name)]\n",
    "        neg_df = df[(df[boundary_col_name] < boundary) & (df['차종'] == model_name)]\n",
    "        \n",
    "    pos_texts = pos_df['리뷰'].apply(ast.literal_eval).sum()\n",
    "    neg_texts = neg_df['리뷰'].apply(ast.literal_eval).sum()\n",
    "    return pos_texts, neg_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드 클라우드 생성\n",
    "def analysis(\n",
    "    texts: List[str],\n",
    "    title: str,\n",
    "    ax: plt.Axes\n",
    ") -> plt.Axes:\n",
    "    wc = WordCloud(\n",
    "        font_path='/Library/Fonts/AppleGothic.ttf',\n",
    "        background_color='white',\n",
    "        width=800, \n",
    "        height=800,\n",
    "        max_words=200,\n",
    "        collocations=False\n",
    "    ).generate(\" \".join(texts))\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.figure.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_with_axes(\n",
    "    posi_texts: list[str],\n",
    "    nega_texts: list[str],\n",
    "    posi_title: str,\n",
    "    nega_title: str,\n",
    "    total_title: str\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 7))\n",
    "    analysis(posi_texts, posi_title, axes[0])\n",
    "    analysis(nega_texts, nega_title, axes[1])\n",
    "    \n",
    "    fig.suptitle(total_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df = extract([\"아반떼\", \"소나타\", \"팰리세이드\", \"포터2\", \"그랜저\", \"아이오닉6\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = transform(extract_df, method='mecab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.to_csv('transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.read_csv('transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts, neg_texts = split_pos_neg_by_spec_col('평점 평균', 7.0, '전체', transformed_df)\n",
    "visualize_with_axes(pos_texts, neg_texts, '긍정', '부정', \"전체 차량\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts, neg_texts = split_pos_neg_by_spec_col('평점 평균', 7.0, '팰리세이드', transformed_df)\n",
    "visualize_with_axes(pos_texts, neg_texts, '긍정', '부정', \"팰리세이드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts, neg_texts = split_pos_neg_by_spec_col('평점 평균', 7.0, '포터2', transformed_df)\n",
    "visualize_with_axes(pos_texts, neg_texts, '긍정', '부정', \"포터2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
