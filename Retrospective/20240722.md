## 팀 회고 진행

- [Notion Link](https://patrashu.notion.site/Day-16-e275dd74362e4a69a4b4edfb73e620d5?pvs=4)

### 리뷰
- 주제를 정하려고 노력했지만, 잘 떠오르지 않는다. 어떤 주제가 사이드 프로젝트로 적합하고, 실현 가능하고, 빅데이터를 이영하고, 금전적인 가치가 있는지 모든 요소를 고려하는 것이 너무 어렵다.
- Spark에 대한 기본 개념을 숙지하는 시간을 가졌습니다.
- hadoop의 cluster ID라는 것을 알게 되었습니다.

### Keep Problem Try
- Keep
    - 결과는 나오지 않았지만, 주제 선정을 위해 열심히 노력했습니다.
- Problem
    - 창의성이 부족하다.
    - 데이터를 모으고 살펴봐야 insight를 찾을 수 있는데, insight를 찾아야 주제가 정해지고, 주제가 정해져야 데이터를 모을 수 있다.
- Try
    - TLC trip record 데이터셋을 사용하기로 결정했으니, 데이터 EDA를 통해 구체적인 주제 방향성을 정하고, 빠르게 피드백을 받도록 한다.


### 개인 회고
- 오늘은 16알차이며, 벌써 4주차에 들어섰다. 저번 주부터 꾸준히 팀원들과 주제를 빌딩하고 있는데, 여러가지 많은 부분들을 고려하다보니 주제 선정에 있어 어려움을 겪고 있다. excel에 있는 선정 기준에 맞춰서 뭔가를 해보려고 하는데, 너무 어렵게 생각하는 것인지 브레인스토밍이 부족한 것인지는 모르겟지만, 과제 2번에서 주어진 데이터셋을 활용하여 주제를 구체화하고 프로토타입을 개발해보고자 한다.

- Hadoop에 이어 Spark개념을 공부했다. 두 가지 Tool은 DE에서 가장 많이 쓰이는 도구이며, 몸에 익숙해질때까지 반복학습할 예정이다. Spark를 빌드할 때 Spark만 다운로드 받을 수 있고 Spark와 Hadoop을 같이 설치할 수 있는 옵션이 존재하는데, 전주까지 개발했던 Hadoop 환경에 올려서 써야하는건지 아니면 그냥 hadoop도 있는 이미지를 깔아서 쓰면 되는지는 좀 더 고민해보고자 한다.