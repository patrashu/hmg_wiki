## 팀 회고 진행

- [Notion Link](https://patrashu.notion.site/Day-19-1f8edc725e804486a5de78e6ef4406ee?pvs=4)

### 팀 리뷰

- 영일: 과제 1/2 개발 환경(도커 컨테이너 빌드 과정) 정리 및 미션2 진행 중
- 이구: mission 2 하는 중. 날씨 관련 데이터 찾아보고 있습니다
- 공통: 프로토타입 개발을 위해 데이터 분석 중

### Keep Problem Try

- Keep
    - 새로운 내용을 공부할 때 최대한 공식 docs를 기반으로 공부하려고 노력했습니다.
    - 다른 교육생 분이 모르는거 질문해주셨을 때 잘 대답해줄 수 있었습니다.
- Problem
    - 오늘은 딱히 문제되는 일이 발생하지 않은 것 같습니다.
- Try
    - pass

### 개인 회고

- 오늘은 프로토타입 개발을 위해 NYC TLC Trip Record Dataset 분석을 진행했다. 데이터 분석을 진행하면서 과제 2번도 함께 해결 중인데, Spark Dataframe의 명령어가 Pandas와 많이 다른 것같다. 생각보다 안되는 코드들이 많아서 공식 문서/GPT와 소통하며 문제를 해결해나가고 있다.

- 날씨 데이터를 추가하여 데이터 분석을 진행하는 부분에서, 날씨 데이터 셋을 다운받기 위해 다양한 게시물들을 찾아보았으며, 내가 원하는 날짜의 데이터를 포함한 날씨 데이터셋을 확보할 수 있었다. 과제의 가장 첫 번째 목표가 "다양한 기간 내 데이터 셋을 효율적으로 처리할 수 있어야 한다"이며, Kaggle이나 타인이 일부 추출해둔 weather정보로 데이터 분석을 진행하는 것은 근본적인 목표에 가깝지 않다고 생각했다. 데이터 탐색을 진행하며 중간에 그냥 타인이 만들어 둔 것을 쓸까하다가, 원하는 Data Product이 나오려면 원하는 데이터를 수집하는 능력이 필요하다고 생각했다. 그래서 [해당 링크](https://www.ncei.noaa.gov/data/global-hourly/archive/csv/)에서 원하는 연도의 날씨 데이터를 다운로드 받았다.

- NYC Central Park에 기후 관측소가 있는 것으로 확인했고, 해당 위도/경도에 해당하는 csv file을 찾기 위해 python 코드를 기반으로 만개 이상의 csv file 탐색을 진행했다. 해당 과정을 수행하면서 하나 의문이 들었던 것은, "단 한개의 의미있는 파일을 추출하기 위해 수만개의 파일을 모두 확인해야하는가?"이다. 확인해야 할 데이터가 더 많은 상황 속에서 내가 추출하고자 하는 데이터가 있을수도/없을수도 있고, 있다고 해서 의미있는 데이터인지도 모르는 상황에 엄청나게 많은 데이터를 확인하는 것이 적절한 행동인지 의문이다. 또한, 실제 현업과 같은 환경에서 데이터를 확보하는 것이 굉장히 어렵다는 것을 몸소 느끼게 되었던 시간이었다.