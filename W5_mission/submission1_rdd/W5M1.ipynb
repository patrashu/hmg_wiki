{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed20cf7-0a3b-4a00-bb57-a819c3952737",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1241ae04-7cd6-4b5d-a19e-e8eaea6acce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /usr/local/lib/python3.10/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c166ee2c-2cbe-4e77-ab50-19f070acb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e82a99-898e-485b-8e8f-6f0c0c2f8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf61052-88d7-48c3-bf73-ad3a97b7f46d",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0a7b3d-9b36-4c06-9b7d-14ef42d39a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(spark: SparkSession, output_dir: str, start_date: str, end_date: str):\n",
    "    sy, sm = start_date.split('-')\n",
    "    ey, em = end_date.split('-')\n",
    "    tmp_df = []\n",
    "    for year in range(int(sy), int(ey)+1):\n",
    "        for month in range(1, 13):\n",
    "            if year == int(sy) and month < int(sm):\n",
    "                continue\n",
    "            if year == int(ey) and month > int(em):\n",
    "                continue\n",
    "            file_path = f'{output_dir}/fhvhv_tripdata_{year}-{str(month).zfill(2)}.parquet'\n",
    "            tmp_df.append(spark.read.parquet(file_path))\n",
    "\n",
    "    if len(tmp_df) == 1:\n",
    "        return tmp_df[0]\n",
    "    else:\n",
    "        tmp = tmp_df[0]\n",
    "        for idx in range(1, len(tmp_df)):\n",
    "            tmp = tmp.union(tmp_df[idx])\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c50d36-e918-4671-a810-bd8eb0be2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(row):\n",
    "    \"\"\"Remove missing/invalid data\"\"\"\n",
    "    try:\n",
    "        pickup_datetime, trip_mile, base_passenger_fare = row\n",
    "        if not all([\n",
    "            pickup_datetime is not None,\n",
    "            trip_mile is not None,\n",
    "            base_passenger_fare is not None\n",
    "        ]):\n",
    "            return False\n",
    "\n",
    "        if trip_mile <= 0. or base_passenger_fare <= 0.:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in row validation: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb44e0-3b10-41f2-a7b6-63d57615f942",
   "metadata": {},
   "source": [
    "## Run SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d110557f-d185-42af-b4bf-58417a72be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/03 23:26:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"NYC Taxi Data Analysis\") \\\n",
    "    .setMaster(\"spark://spark-master:7077\") \\\n",
    "    .set(\"spark.executor.memory\", \"20g\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8f66a7-312e-41aa-8cb5-8223f1337a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"hdfs://spark-master:9000/data\"\n",
    "result_dir = \"hdfs://spark-master:9000/result\"\n",
    "start_date = \"2023-01\"\n",
    "end_date = \"2023-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85d26fe-ad4f-4f0f-b999-36518b79fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load dataframe from hdfs\n",
    "df = merge_data(spark, output_dir, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad93637-d12a-4281-ae03-fda0d20f8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_data = df.rdd.map(lambda row: (\n",
    "    row.pickup_datetime,\n",
    "    row.trip_miles,\n",
    "    row.base_passenger_fare\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e682b45-3a82-4fbe-b090-27538ec131c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data\n",
    "parsed_data = rdd_data.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02c94cf-8f1f-4202-bbd8-540c62f0bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "valid_data = parsed_data.filter(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e222743-2649-4831-aa39-c8d3cd7f478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15438062-2acc-4006-b9e0-2e32c6641189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trips: 18462090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# count total trips\n",
    "try:\n",
    "    total_trips = valid_data.count()\n",
    "    print(f\"Total Trips: {total_trips}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while counting valid_data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15af74a2-c8a0-4577-be28-b997590ae4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Revenue: $398359394.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sumation total revenue\n",
    "try:\n",
    "    total_revenue = valid_data.map(lambda x: x[2]).sum()\n",
    "    print(f\"Total Revenue: ${total_revenue:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while calculating total revenue: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d0a01a-45c0-4cf5-a7e9-0b40950e5eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Trip Distance: 4.87 mile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calcaulate avg_trip_dist\n",
    "try:\n",
    "    avg_trip_distance = valid_data.map(lambda x: x[1]).mean()\n",
    "    print(f\"Average Trip Distance: {avg_trip_distance:.2f} mile\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while calculating avg trip distance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b50b8d-3426-4684-a5b6-55b821c0e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by date\n",
    "try:\n",
    "    trips_by_date = valid_data.map(lambda x: (x[0].date(), 1)).reduceByKey(lambda a, b: a + b)\n",
    "    trips_by_date.saveAsTextFile(f\"{output_dir}/trips_by_date\")\n",
    "except:\n",
    "    print(f\"Error while calculating trips by date: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d0598d-f147-43c7-b170-e732d4db2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    revenue_by_date = valid_data.map(lambda x: (x[0].date(), x[2])).reduceByKey(lambda a, b: a + b)\n",
    "    revenue_by_date.saveAsTextFile(f\"{output_dir}/revenue_by_date\")\n",
    "except:\n",
    "    print(f\"Error while calculating revenue by date: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf85d2a2-2e6f-42fc-8ba0-71fc8fdb7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check txt files\n",
    "file_path = \"hdfs://spark-master:9000/data/trips_by_date/part*\"\n",
    "trip_res = sc.textFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e08b5d4-9975-4b0b-bcc2-bf47ca3f013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(datetime.date(2023, 1, 8), 554835)',\n",
       " '(datetime.date(2023, 1, 3), 477381)',\n",
       " '(datetime.date(2023, 1, 25), 660974)',\n",
       " '(datetime.date(2023, 1, 29), 620561)',\n",
       " '(datetime.date(2023, 1, 21), 752711)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_res.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9f3ce50-8619-44c3-b908-78b3620537a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check txt files\n",
    "file_path = \"hdfs://spark-master:9000/data/revenue_by_date/part*\"\n",
    "renevue_res = sc.textFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bdfa4ff-f971-4150-879b-c53f15b6e009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(datetime.date(2023, 1, 8), 11725043.3200018)',\n",
       " '(datetime.date(2023, 1, 3), 10433854.660002572)',\n",
       " '(datetime.date(2023, 1, 25), 14253913.040001681)',\n",
       " '(datetime.date(2023, 1, 29), 13272687.439999817)',\n",
       " '(datetime.date(2023, 1, 21), 15295015.960000405)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renevue_res.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
